#!/usr/bin/env python3
"""
Stock Analyzer - End-to-End ì¢…ëª© ë¶„ì„ ë° ìˆœìœ„ ì‚°ì • (Yahoo Finance + DART/PyKRX)

ì‚¬ìš©ë²•:
    # íŠ¹ì • ì¢…ëª© ë¶„ì„
    python analyze_stocks.py --tickers AAPL,GOOGL,MSFT,NVDA,TSLA

    # S&P 500 ì „ì²´ ë¶„ì„ (--top ìƒëµ ì‹œ ì „ì²´ ì¢…ëª© ë¶„ì„)
    python analyze_stocks.py --index sp500

    # S&P 500 ìƒìœ„ 30ê°œë§Œ ë¶„ì„
    python analyze_stocks.py --index sp500 --top 30

    # KOSPI ì‹œê°€ì´ì•¡ ìƒìœ„ 30ê°œ ë¶„ì„
    python analyze_stocks.py --index kospi --top 30

    # KOSDAQ 150 ë¶„ì„
    python analyze_stocks.py --index kosdaq150

    # KRX ì „ì²´ (KOSPI + KOSDAQ) ë¶„ì„
    python analyze_stocks.py --index krx

    # ê²°ê³¼ë¥¼ íŒŒì¼ë¡œ ì €ì¥
    python analyze_stocks.py --index sp500 --output results.json

    # ìºì‹œ ì—†ì´ ì‹¤í–‰
    python analyze_stocks.py --index sp500 --no-cache

    # ìºì‹œ ì‚­ì œ
    python analyze_stocks.py --clear-cache

    # Wikipedia/PyKRXì—ì„œ ìµœì‹  í‹°ì»¤ ëª©ë¡ ê°±ì‹ 
    python analyze_stocks.py --index sp500 --update-tickers
"""
import sys
import json
import argparse
from datetime import datetime

import config
from cache import clear_cache, get_cache_stats, cache_stats
from data_fetcher import get_index_tickers, sort_tickers_by_market_cap
from analysis import run_batch_analysis
from reporting import print_results
from ticker_utils import is_korean_index, is_korean_ticker


def main():
    parser = argparse.ArgumentParser(
        description="ì¢…ëª© ë¶„ì„ ë° 1ë…„ í›„ ìˆ˜ìµë¥  ì˜ˆì¸¡",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ì˜ˆì‹œ:
  # íŠ¹ì • ì¢…ëª© ë¶„ì„
  uv run python analyze_stocks.py --tickers AAPL,GOOGL,MSFT

  # S&P 500 ì „ì²´ ë¶„ì„ (--top ë¯¸ì§€ì • ì‹œ ì „ì²´)
  uv run python analyze_stocks.py --index sp500

  # NASDAQ 100 ìƒìœ„ 20ê°œë§Œ ë¶„ì„
  uv run python analyze_stocks.py --index nasdaq100 --top 20

  # KOSPI ì‹œê°€ì´ì•¡ ìƒìœ„ 30ê°œ ë¶„ì„
  uv run python analyze_stocks.py --index kospi --top 30

  # KOSDAQ 150 ì „ì²´ ë¶„ì„
  uv run python analyze_stocks.py --index kosdaq150

  # KRX ì „ì²´ (KOSPI + KOSDAQ) ë¶„ì„
  uv run python analyze_stocks.py --index krx

  # í•œêµ­ íŠ¹ì • ì¢…ëª© ë¶„ì„ (ì‚¼ì„±ì „ì, SKí•˜ì´ë‹‰ìŠ¤)
  uv run python analyze_stocks.py --tickers 005930,000660

  # ê²°ê³¼ ì €ì¥
  uv run python analyze_stocks.py --index sp500 --output results.json
        """
    )
    parser.add_argument("--tickers", type=str, help="ë¶„ì„í•  ì¢…ëª© (ì½¤ë§ˆ êµ¬ë¶„)")
    parser.add_argument("--index", type=str, choices=["sp500", "nasdaq100", "kospi", "kosdaq", "kospi200", "kosdaq150", "krx"], help="ì¸ë±ìŠ¤ ì „ì²´ ë¶„ì„ (krx = KOSPI200+KOSDAQ150 ëŒ€í‘œ ì¢…ëª©)")
    parser.add_argument("--top", type=int, default=None, help="ë¶„ì„ ëŒ€ìƒ ì¢…ëª© ìˆ˜ ì œí•œ (ë¯¸ì§€ì • ì‹œ ì „ì²´ ì¢…ëª© ë¶„ì„)")
    parser.add_argument("--strategy", type=str, default="hybrid",
                       choices=["fundamental", "momentum", "hybrid"],
                       help="ë¶„ì„ ì „ëµ: fundamental(í€ë”ë©˜í„¸), momentum(ëª¨ë©˜í…€), hybrid(í˜¼í•©) (ê¸°ë³¸: hybrid)")
    parser.add_argument("--no-sort-by-cap", action="store_false", dest="sort_by_cap",
                       help="ì‹œê°€ì´ì•¡ ì •ë ¬ ë¹„í™œì„±í™” (ê¸°ë³¸: ì‹œê°€ì´ì•¡ ë‚´ë¦¼ì°¨ìˆœ ì •ë ¬)")
    parser.set_defaults(sort_by_cap=True)
    parser.add_argument("--workers", type=int, default=config.MAX_WORKERS, help=f"ë³‘ë ¬ ì²˜ë¦¬ ì›Œì»¤ ìˆ˜ (ê¸°ë³¸: {config.MAX_WORKERS})")
    parser.add_argument("--output", type=str, help="ê²°ê³¼ ì €ì¥ íŒŒì¼ (JSON)")
    parser.add_argument("--period", type=str, default=config.DEFAULT_PERIOD, help="ì˜ˆì¸¡ ê¸°ê°„ (ê¸°ë³¸: 1Y)")
    parser.add_argument("--no-cache", action="store_true", help="ìºì‹œ ì‚¬ìš© ì•ˆ í•¨ (í•­ìƒ API í˜¸ì¶œ)")
    parser.add_argument("--clear-cache", action="store_true", help="ìºì‹œ ì‚­ì œ í›„ ì¢…ë£Œ")
    parser.add_argument("--cache-stats", action="store_true", help="ìºì‹œ í†µê³„ ì¶œë ¥ í›„ ì¢…ë£Œ")
    parser.add_argument("--update-tickers", action="store_true", help="Wikipedia/PyKRXì—ì„œ ìµœì‹  í‹°ì»¤ ëª©ë¡ ê°±ì‹ ")

    args = parser.parse_args()

    # ìºì‹œ ê´€ë ¨ ëª…ë ¹ ì²˜ë¦¬
    if args.clear_cache:
        clear_cache()
        sys.exit(0)

    if args.cache_stats:
        stats = get_cache_stats()
        print(f"\nğŸ“¦ ìºì‹œ í†µê³„")
        print(f"   - ìºì‹œ íŒŒì¼ ìˆ˜: {stats['total_files']}ê°œ")
        print(f"   - ìºì‹œ í¬ê¸°: {stats['total_size_mb']} MB")
        print(f"   - ìºì‹œëœ ë‚ ì§œ: {', '.join(stats['dates'][:5]) if stats['dates'] else 'ì—†ìŒ'}")
        sys.exit(0)

    # ìºì‹œ ë¹„í™œì„±í™”
    if args.no_cache:
        config.CACHE_ENABLED = False
        print("âš ï¸  ìºì‹œ ë¹„í™œì„±í™”ë¨ - ëª¨ë“  ë°ì´í„°ë¥¼ APIì—ì„œ ê°€ì ¸ì˜µë‹ˆë‹¤.")

    # ì¢…ëª© ë¦¬ìŠ¤íŠ¸ ê²°ì •
    if args.tickers:
        tickers = [t.strip() for t in args.tickers.split(',')]
    elif args.index:
        use_ticker_cache = config.CACHE_ENABLED and not args.update_tickers
        tickers = get_index_tickers(args.index, use_cache=use_ticker_cache)
    else:
        print("ì˜¤ë¥˜: --tickers ë˜ëŠ” --index ì¤‘ í•˜ë‚˜ë¥¼ ì§€ì •í•´ì•¼ í•©ë‹ˆë‹¤.")
        parser.print_help()
        sys.exit(1)

    # ì‹œê°€ì´ì•¡ ê¸°ì¤€ ì •ë ¬ (ê¸°ë³¸ê°’: í™œì„±í™”, --no-sort-by-capìœ¼ë¡œ ë¹„í™œì„±í™”)
    if args.sort_by_cap and tickers:
        tickers = sort_tickers_by_market_cap(tickers, top_n=args.top if args.top else 0)
    elif args.top and len(tickers) > args.top:
        tickers = tickers[:args.top]

    end_date = datetime.now().strftime("%Y-%m-%d")
    strategy_names = {"fundamental": "í€ë”ë©˜í„¸", "momentum": "ëª¨ë©˜í…€", "hybrid": "í•˜ì´ë¸Œë¦¬ë“œ"}

    # ë°ì´í„° ì†ŒìŠ¤ ìë™ ê°ì§€
    is_kr = (args.index and is_korean_index(args.index)) or (args.tickers and all(is_korean_ticker(t.strip()) for t in args.tickers.split(',')))
    data_source = "DART + PyKRX" if is_kr else "Yahoo Finance"

    print(f"\n{'='*60}")
    print(f"ğŸ” AI Hedge Fund - ì¢…ëª© ë¶„ì„ ì‹œìŠ¤í…œ ({data_source})")
    print(f"{'='*60}")
    print(f"ë¶„ì„ ë‚ ì§œ: {end_date}")
    print(f"ì˜ˆì¸¡ ê¸°ê°„: {args.period}")
    print(f"ë¶„ì„ ì „ëµ: {strategy_names.get(args.strategy, args.strategy)}")
    print(f"ëŒ€ìƒ ì¢…ëª©: {len(tickers)}ê°œ")
    print()

    # ë¶„ì„ ì‹¤í–‰
    results = run_batch_analysis(tickers, end_date, args.workers, strategy=args.strategy)

    if not results:
        print("ë¶„ì„ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
        sys.exit(1)

    # ê²°ê³¼ ì¶œë ¥
    print_results(results, args.top, strategy=args.strategy)

    # ìºì‹œ í†µê³„ ì¶œë ¥
    if config.CACHE_ENABLED:
        total_requests = cache_stats["hits"] + cache_stats["misses"]
        if total_requests > 0:
            hit_rate = cache_stats["hits"] / total_requests * 100
            print(f"\nğŸ’¾ ìºì‹œ í†µê³„: {cache_stats['hits']}/{total_requests} íˆíŠ¸ ({hit_rate:.0f}%), API í˜¸ì¶œ {cache_stats['misses']}íšŒ ì ˆê°")

    # íŒŒì¼ ì €ì¥
    strategy_methods = {
        "fundamental": "Ensemble multi-factor analysis (Value + Growth + Quality + Momentum + Safety)",
        "momentum": "Enhanced momentum analysis (Short/Long momentum + RSI + Trend)",
        "hybrid": "Hybrid analysis (70% Fundamental + 30% Enhanced Momentum, Lynch GARP bonus)",
    }
    if args.output:
        output_data = {
            "analysis_date": end_date,
            "prediction_period": args.period,
            "strategy": args.strategy,
            "total_analyzed": len(results),
            "methodology": strategy_methods.get(args.strategy, "Multi-factor analysis"),
            "factor_weights": config.FACTOR_WEIGHTS,
            "rankings": results
        }
        with open(args.output, 'w', encoding='utf-8') as f:
            json.dump(output_data, f, indent=2, ensure_ascii=False)
        print(f"\nê²°ê³¼ ì €ì¥ë¨: {args.output}")


if __name__ == "__main__":
    main()
